{
 "cells": [
  {
   "source": [
    "# Feature Engineering of the Housing Dataset.\n",
    "\n",
    "Feature engineering efforts mainly have two goals:\n",
    "- Preparing the proper input dataset, compatible with the machine learning algorithm requirements.\n",
    "- Improving the performance of machine learning models.\n",
    "\n",
    "In this notebook, I am trying to improve OLS model by feature engineering. Models explained:\n",
    "- **Model 1:** Linear Regression with original features\n",
    "- **Model 2:** To regularize the OLS regression with an L1-L2 penalty term, use Elastic Net with original features. Note: This type of regularization becomes quite powerful when we have many regressors.\n",
    "- **Model 3:** To further improve Elastic Net, add more features\n",
    "\n",
    "Goal:\n",
    "- (a) Add at least 10 more regressors by applying non-linear transformations to the features in the dataset. Make pipelines of transformers.\n",
    "- (b) Fit the Elastic Net model (**Model 3**) and see if we have improvement on the MSE obtained by OLS (**Model 1**).\n",
    "    - Run a 10-fold cross validation on the training set to find the MSE distribution of new Elastic Net (**Model 3**), and \n",
    "    - compare it to the MSE distribution of the OLS model  (**Model 1**) \n",
    "    - See any improvements both on the bias and variance?\n",
    "    - For each set of features added, find the optimal elastic net model using a grid search of the parameter space. Does the best model remain the best in terms of MSE of the test set? Explain."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\xxxli\\Anaconda3\\envs\\mysixenv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\xxxli\\Anaconda3\\envs\\mysixenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\nC:\\Users\\xxxli\\Anaconda3\\envs\\mysixenv\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20635</th>\n      <td>-121.09</td>\n      <td>39.48</td>\n      <td>25.0</td>\n      <td>1665.0</td>\n      <td>374.0</td>\n      <td>845.0</td>\n      <td>330.0</td>\n      <td>1.5603</td>\n      <td>78100.0</td>\n      <td>INLAND</td>\n    </tr>\n    <tr>\n      <th>20636</th>\n      <td>-121.21</td>\n      <td>39.49</td>\n      <td>18.0</td>\n      <td>697.0</td>\n      <td>150.0</td>\n      <td>356.0</td>\n      <td>114.0</td>\n      <td>2.5568</td>\n      <td>77100.0</td>\n      <td>INLAND</td>\n    </tr>\n    <tr>\n      <th>20637</th>\n      <td>-121.22</td>\n      <td>39.43</td>\n      <td>17.0</td>\n      <td>2254.0</td>\n      <td>485.0</td>\n      <td>1007.0</td>\n      <td>433.0</td>\n      <td>1.7000</td>\n      <td>92300.0</td>\n      <td>INLAND</td>\n    </tr>\n    <tr>\n      <th>20638</th>\n      <td>-121.32</td>\n      <td>39.43</td>\n      <td>18.0</td>\n      <td>1860.0</td>\n      <td>409.0</td>\n      <td>741.0</td>\n      <td>349.0</td>\n      <td>1.8672</td>\n      <td>84700.0</td>\n      <td>INLAND</td>\n    </tr>\n    <tr>\n      <th>20639</th>\n      <td>-121.24</td>\n      <td>39.37</td>\n      <td>16.0</td>\n      <td>2785.0</td>\n      <td>616.0</td>\n      <td>1387.0</td>\n      <td>530.0</td>\n      <td>2.3886</td>\n      <td>89400.0</td>\n      <td>INLAND</td>\n    </tr>\n  </tbody>\n</table>\n<p>20640 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"Data_Science_Applications\\Housing_Feature_Engineering_DS6\\datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    \n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "        \n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    if not os.path.isfile(tgz_path): #download data if not already there\n",
    "        urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "        \n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Split:\n",
    "\n",
    "* Training X: ``housing_train_X``\n",
    "* Training y:``housing_labels_train_y``\n",
    "* Testing X: ``housing_test_X``\n",
    "* Testing y: ``housing_labels_test_y``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# to make this notebook's output identical at every run\n",
    "np.random.seed(42)\n",
    "\n",
    "# Divide by 1.5 to limit the number of income categories\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "# Label those above 5 as 5\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "strat_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_X = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels_train_y = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_test_X = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels_test_y = strat_test_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split the training set into numerical and Categorical parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training set into numerical and Categorical parts\n",
    "housing_num = housing_train_X.drop(\"ocean_proximity\", axis=1)\n",
    "housing_cat = housing_train_X[\"ocean_proximity\"]\n",
    "\n",
    "# dealing with missing numerical value\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# dealing with categorical value\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "source": [
    "Create a class to select numerical or categorical columns \n",
    "since Scikit-Learn doesn't handle DataFrames yet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "source": [
    "Let's create our own transformer which transformes all our numerical variables\n",
    "- Note that the BaseEstimator is the abstract class we need to always inherit from. \n",
    "- The TransformerMixin class basically adds the fit_transform() method once the fit() \n",
    "- and transform() methods are implemented"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# coln index\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "# combine in pipline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()), # a stransformer which scales the variables \n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "source": [
    "Then, dealing with categorical ones:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelBinarizer is same as OneHotEncoder but fit_transform() equivalent to fit_transform().to_array() of OneHotEncoder\n",
    "# unfortunately LabelBinarizer isn't pipeline friendly so we'll have to extend it as below:\n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "class PipelineFriendlyLabelBinarizer(LabelBinarizer):\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(PipelineFriendlyLabelBinarizer, self).fit_transform(X)\n",
    "\n",
    "# dealing with categorical \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat)\n",
    "# already have housing_cat_encoded\n",
    "ppflb = PipelineFriendlyLabelBinarizer()\n",
    "housing_cat_1hot_lb = ppflb.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "housing_cat_1hot_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Pipline for preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's now combine the numerical and categorical pipelines\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', PipelineFriendlyLabelBinarizer()),\n",
    "    ])\n",
    "\n",
    "# and concatenate them with FeatureUnion class\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "# this is the final transformation result!\n",
    "housing_train_X_prepared = full_pipeline.fit_transform(housing_train_X)\n",
    "housing_test_X_prepared = full_pipeline.transform(housing_test_X)\n",
    "housing_train_X_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ready for Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on testing set: [424327.91587129 264520.09425443 228109.45155968 ... 290423.67564301\n",
      " 192142.16080923 151202.36199678]\n",
      "Actual Values of testing set: \n",
      " 5241     500001.0\n",
      "10970    240300.0\n",
      "20351    218200.0\n",
      "6568     182100.0\n",
      "13285    121300.0\n",
      "           ...   \n",
      "20519     76400.0\n",
      "17430    134000.0\n",
      "4019     311700.0\n",
      "12107    133500.0\n",
      "2398      78600.0\n",
      "Name: median_house_value, Length: 4128, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_train_X_prepared, housing_labels_train_y)\n",
    "\n",
    "print(\"Predictions on testing set:\", lin_reg.predict(housing_test_X_prepared))\n",
    "print('Actual Values of testing set: \\n',housing_labels_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Pipline for Preparation & Prediction:\n",
    "##### Predictorï¼šLinear Regressionï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_with_predictor_linreg = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor_linreg.fit(housing_train_X, housing_labels_train_y)\n",
    "\n",
    "prediction_on_train_linreg = full_pipeline_with_predictor_linreg.predict(housing_train_X)\n",
    "prediction_on_test_linreg = full_pipeline_with_predictor_linreg.predict(housing_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictorï¼šElastic Net (default L1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "full_pipeline_with_predictor_enet = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", ElasticNet(random_state=0))\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor_enet.fit(housing_train_X, housing_labels_train_y)\n",
    "\n",
    "prediction_on_train_enet = full_pipeline_with_predictor_enet.predict(housing_train_X)\n",
    "prediction_on_test_enet = full_pipeline_with_predictor_enet.predict(housing_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at Distribution of MSE from each model by 10-fold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "count    1.000000e+01\n",
      "mean     4.775625e+09\n",
      "std      4.023328e+08\n",
      "min      4.221053e+09\n",
      "25%      4.507385e+09\n",
      "50%      4.645265e+09\n",
      "75%      5.038537e+09\n",
      "max      5.585961e+09\n",
      "dtype: float64\n",
      "\n",
      "Elastic Net\n",
      "count    1.000000e+01\n",
      "mean     6.195185e+09\n",
      "std      2.989564e+08\n",
      "min      5.806348e+09\n",
      "25%      6.022578e+09\n",
      "50%      6.137844e+09\n",
      "75%      6.318498e+09\n",
      "max      6.703124e+09\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# by CV, see distribution of MSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_full_pipeline_with_predictor(predictor):\n",
    "    pipe = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", predictor)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def run_describe_predictors(predictors):\n",
    "    mse_distribution = {}\n",
    "    scores = {}\n",
    "    for name, predictor in predictors.items():\n",
    "        print(name)\n",
    "        pipe = create_full_pipeline_with_predictor(predictor)\n",
    "        scores[name] = cross_val_score(\n",
    "            pipe, housing_train_X, housing_labels_train_y, \n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            cv=10)\n",
    "\n",
    "        mse_distribution[name] = pd.Series(-scores[name])\n",
    "        print(mse_distribution[name].describe())\n",
    "        print('')\n",
    "    return scores, mse_distribution\n",
    "\n",
    "predictors = {'Linear Regression':LinearRegression(), 'Elastic Net': ElasticNet(random_state=0)}\n",
    "\n",
    "scores, mse_distribution = run_describe_predictors(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search for a better Elastic Net param:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=0, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'l1_ratio': [0.125, 0.25, 0.5, 0.75, 0.875]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do a grid search for the best params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "predictor = ElasticNet(random_state=0)\n",
    "param_grid = [\n",
    "    # try varying the ll_ratio and tolerance\n",
    "    {\n",
    "        'l1_ratio': [ 0.125, 0.25, 0.5, 0.75, 0.875],\n",
    "    },\n",
    "  ]\n",
    "grid_search = GridSearchCV(predictor, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_train_X_prepared, housing_labels_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.875,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our best Elastic Net:\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare the Distributions of MSE from \n",
    "* OLS\n",
    "* Elastic Net 0.5\n",
    "* Elastic Net 0.875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "count    1.000000e+01\n",
      "mean     4.775625e+09\n",
      "std      4.023328e+08\n",
      "min      4.221053e+09\n",
      "25%      4.507385e+09\n",
      "50%      4.645265e+09\n",
      "75%      5.038537e+09\n",
      "max      5.585961e+09\n",
      "dtype: float64\n",
      "\n",
      "Elastic Net with l1_ratio 0.5\n",
      "count    1.000000e+01\n",
      "mean     6.195185e+09\n",
      "std      2.989564e+08\n",
      "min      5.806348e+09\n",
      "25%      6.022578e+09\n",
      "50%      6.137844e+09\n",
      "75%      6.318498e+09\n",
      "max      6.703124e+09\n",
      "dtype: float64\n",
      "\n",
      "Elastic Net with l1_ratio 0.875\n",
      "count    1.000000e+01\n",
      "mean     5.057377e+09\n",
      "std      3.069818e+08\n",
      "min      4.593228e+09\n",
      "25%      4.886414e+09\n",
      "50%      5.003651e+09\n",
      "75%      5.286114e+09\n",
      "max      5.527204e+09\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors = {\n",
    "    'Linear Regression':LinearRegression(), \n",
    "    'Elastic Net with l1_ratio 0.5': ElasticNet(random_state=0),\n",
    "    'Elastic Net with l1_ratio 0.875': ElasticNet(random_state=0, l1_ratio=0.875)\n",
    "}\n",
    "_,_ = run_describe_predictors(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "## 3. Feature Engineering of the Housing Dataset.\n",
    "In class we used elastic net to regularize the OLS regression with an L1-L2 penalty term.\n",
    "This type of regularization becomes quite powerful when we have many regressors.\n",
    "### (a) Add more regressors to the problem by applying non-linear transformations of your choice to the features in the dataset. Add at least 10 more regressors by modifying appropriately the pipeline of your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "longitude_ix, latitude_ix, housing_median_age_ix, rooms_ix, bedrooms_ix, population_ix, household_ix, median_income_ix = 0, 1, 2, 3, 4, 5, 6, 7\n",
    "\n",
    "class MyCombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): \n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]                      #47\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]            #67\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]                         #45\n",
    "        bedrooms_per_household = X[:, bedrooms_ix] / X[:, household_ix] #1             #57\n",
    "        longitude_latitude_ratio = X[:, longitude_ix] / X[:, latitude_ix] #2           #12\n",
    "        population_per_room = X[:, population_ix] / X[:, rooms_ix] #3                  #46\n",
    "        population_per_bedroom = X[:, population_ix] / X[:, bedrooms_ix] #4            #56\n",
    "        housing_total_age = X[:, housing_median_age_ix] * X[:, household_ix] #5        #37\n",
    "        housing_total_income = X[:, median_income_ix] * X[:, household_ix] #6          #87\n",
    "        population_total_income = X[:, median_income_ix] * X[:, population_ix] #7      #86\n",
    "        median_age_rooms = X[:, housing_median_age_ix] * X[:, rooms_ix] #8\n",
    "        median_age_bedrooms = X[:, housing_median_age_ix] *  X[:, bedrooms_ix] #9\n",
    "        meidan_income_bedrooms =  X[:, median_income_ix]*X[:, bedrooms_ix] #10\n",
    "        \n",
    "        # population_quadratic =  X[:, population_ix] *  X[:, population_ix] \n",
    "        # housing_median_age_quadratic = X[:, median_income_ix] * X[:, median_income_ix] \n",
    "        # bedroom_quadratic = X[:, bedrooms_ix] * X[:, bedrooms_ix]\n",
    "        \n",
    "        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room, \n",
    "                     bedrooms_per_household, longitude_latitude_ratio, population_per_room, \n",
    "                     population_per_bedroom, housing_total_age, housing_total_income, \n",
    "                     population_total_income, \n",
    "                     median_age_rooms, median_age_bedrooms,meidan_income_bedrooms]\n",
    "                     # population_quadratic, housing_median_age_quadratic, bedroom_quadratic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new full pipline\n",
    "my_num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', MyCombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "my_full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", my_num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Fit the elastic net model and see if you will improve on the MSE obtained in class.\n",
    "### Run a ``10-fold cross validation`` on the training set to find the MSE distribution of your model, and compare it to the MSE distribution of the OLS model with the features used in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net\n",
      "count    1.000000e+01\n",
      "mean     5.766017e+09\n",
      "std      3.689235e+08\n",
      "min      5.398735e+09\n",
      "25%      5.535117e+09\n",
      "50%      5.642344e+09\n",
      "75%      5.888159e+09\n",
      "max      6.445011e+09\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def my_create_full_pipeline_with_predictor(predictor):\n",
    "    pipe = Pipeline([\n",
    "        (\"preparation\", my_full_pipeline),\n",
    "        (\"linear\", predictor)\n",
    "    ])\n",
    "    return pipe\n",
    "\n",
    "def my_run_describe_predictors(predictors):\n",
    "    mse_distribution = {}\n",
    "    scores = {}\n",
    "    for name, predictor in predictors.items():\n",
    "        print(name)\n",
    "        pipe = my_create_full_pipeline_with_predictor(predictor)\n",
    "        scores[name] = cross_val_score(\n",
    "            pipe, housing_train_X, housing_labels_train_y, \n",
    "            scoring=\"neg_mean_squared_error\", # for some reason cross_val_score computes negative of MSE\n",
    "            cv=10) #10-fold cross-validation\n",
    "\n",
    "        mse_distribution[name] = pd.Series(-scores[name])\n",
    "        print(mse_distribution[name].describe())\n",
    "        print('')\n",
    "    return scores, mse_distribution\n",
    "\n",
    "my_predictors = {'Elastic Net': ElasticNet(random_state=0)}\n",
    "my_scores, my_mse_distribution = my_run_describe_predictors(my_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "count    1.000000e+01\n",
      "mean     4.775625e+09\n",
      "std      4.023328e+08\n",
      "min      4.221053e+09\n",
      "25%      4.507385e+09\n",
      "50%      4.645265e+09\n",
      "75%      5.038537e+09\n",
      "max      5.585961e+09\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inclass_predictors = {'Linear Regression':LinearRegression()}\n",
    "_, inclass_mse_distribution = run_describe_predictors(inclass_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE ENet / MSE OLS = 1.2073849074589555\n",
      "  Var ENet = 1.3610451747521131e+17\n",
      "  Var OLS = 1.618717209364811e+17\n",
      "Var ENet / Var OLS = 0.8408171401885516\n"
     ]
    }
   ],
   "source": [
    "print('MSE ENet / MSE OLS =', my_mse_distribution['Elastic Net'].mean()/ inclass_mse_distribution['Linear Regression'].mean())\n",
    "print('  Var ENet =', my_mse_distribution['Elastic Net'].std()**2)\n",
    "print('  Var OLS =', inclass_mse_distribution['Linear Regression'].std() **2)\n",
    "print('Var ENet / Var OLS =', my_mse_distribution['Elastic Net'].std()**2/inclass_mse_distribution['Linear Regression'].std() **2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compareï¼š\n",
    "\n",
    "**How about bias?**\n",
    "\n",
    "bias of OLS  = 0 since OLS estimator is BLUE.\n",
    "\n",
    "**Is there a biased estimator is better than OLS estimator in terms of MSE?**\n",
    "\n",
    "My Elastic Net produces worse results than in-class OLS in terms of mean of MSE,\n",
    "its MSE is about **20%** bigger than in-class OLS MSE.\n",
    "\n",
    "(But my Elastic Net is better than the Elastic Net in class whose MSE is about 30% bigger than OLS.)\n",
    "\n",
    "However, it is **not fair** if we compare two models by only looking at MSE, since\n",
    "**MSE can be decomposited into two components: bias contribution + variance contribution** \n",
    "\n",
    "What we have now is:\n",
    "\n",
    "var(in-class OLS above) = 4.023328e+08 ^2 **>** var(my ElaNet) = 3.689235e+08 ^2\n",
    "\n",
    "My Elastic Net in general has a much **lower variance** than in-class OLS. i.e. In-class OLS almost doubles mine.\n",
    "\n",
    "\n",
    "### Can you improve both on the bias and variance? NO, I cannot (OLS is already unbiased) and I didn't, since\n",
    "**Above all:**\n",
    "* MSE(ElaNet) > MSE(OLS)\n",
    "* Bias(ElaNet) > Bias(OLS) = 0\n",
    "* Var(ElaNet) < Var(OLS)\n",
    "\n",
    "**Notice that we are increasing the MSE in ElaNet by adding a little bit of bias but also decreasing variance a lot.**\n",
    "\n",
    "We know that it is **not fair** if we compare two models by only looking at MSE.\n",
    "\n",
    "It is bad, of course, if we increasing MSE and Variance at the same time (although it is quite often that we may increase bias and variance at the same time).\n",
    "\n",
    "**Therefore, here we got a good scenario in my Elastic Net Model with Bias goes up a little bit but Variance goes down a lot.**\n",
    "\n",
    "---------\n",
    "To have a look of my elastic net performance, I want to further optimize our Elastic Net model by changing ``L1_ratio``, and compare the optimized Elastic Net performance with OLS on **test set**.\n",
    "\n",
    "### For each set of features you consider, find the optimal elastic net model using a grid search of the parameter space. Does your best model remain the best in terms of MSE of the test set? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data by my new created pipline:\n",
    "my_housing_train_X_prepared = my_full_pipeline.fit_transform(housing_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.975,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=0, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for the best params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_predictor = ElasticNet(random_state=0)\n",
    "my_param_grid = [\n",
    "    # l1_ratio = alpha/rho\n",
    "    {\n",
    "        'l1_ratio': [ 0.125, 0.25, 0.5, 0.75, 0.875, 0.9, 0.95, 0.975],\n",
    "    },\n",
    "  ]\n",
    "my_grid_search = GridSearchCV(target_predictor, my_param_grid, cv=10,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "my_grid_search.fit(my_housing_train_X_prepared, housing_labels_train_y)\n",
    "optimal_Elastic_Net = my_grid_search.best_estimator_\n",
    "optimal_Elastic_Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE on TESTING SET :\n",
    "* OLS \n",
    "* my optimal Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of inclass OLS: 4477213162.344775\n",
      "MSE of my Optimal Elastic Net: 4416153774.006561\n",
      "MSE ENet Optimal / MSE OLS: 0.9863621886820693\n"
     ]
    }
   ],
   "source": [
    "# Inclass OLS predictions on testing\n",
    "prediction_on_test_linreg = full_pipeline_with_predictor_linreg.predict(housing_test_X)\n",
    "\n",
    "# My optimal Elastic Net predictions on testing\n",
    "my_optimal_full_pipeline_with_predictor_enet = Pipeline([\n",
    "        (\"preparation\", my_full_pipeline),\n",
    "        (\"linear\", optimal_Elastic_Net)\n",
    "    ])\n",
    "my_optimal_full_pipeline_with_predictor_enet.fit(housing_train_X, housing_labels_train_y)\n",
    "prediction_on_test_enet_optimal = my_optimal_full_pipeline_with_predictor_enet.predict(housing_test_X)\n",
    "\n",
    "\n",
    "# mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse = mean_squared_error(housing_labels_test_y, prediction_on_test_linreg)\n",
    "enet_mse = mean_squared_error(housing_labels_test_y, prediction_on_test_enet_optimal)\n",
    "\n",
    "print('MSE of inclass OLS:',lin_mse)\n",
    "print('MSE of my Optimal Elastic Net:', enet_mse)\n",
    "print('MSE ENet Optimal / MSE OLS:',enet_mse/lin_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In terms of MSE on TESTING SET, my optimal Elastic Net model improves the prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on Test Set when L1_ratio=0.125: 6367458023.8448\n",
      "MSE on Test Set when L1_ratio=0.25: 6129324734.859161\n",
      "MSE on Test Set when L1_ratio=0.5: 5593427085.613493\n",
      "MSE on Test Set when L1_ratio=0.75: 4970958349.3001795\n",
      "MSE on Test Set when L1_ratio=0.875: 4641864935.072175\n",
      "MSE on Test Set when L1_ratio=0.9: 4578922023.980293\n",
      "MSE on Test Set when L1_ratio=0.95: 4463632316.049739\n",
      "MSE on Test Set when L1_ratio=0.975: 4416153774.006561\n",
      "MSE on Test Set of inclass OLS: 4477213162.344775\n"
     ]
    }
   ],
   "source": [
    "param = [ 0.125, 0.25, 0.5, 0.75, 0.875, 0.9, 0.95, 0.975]\n",
    "pds = [ElasticNet(random_state=0, l1_ratio=l) for l in param]\n",
    "pls = [my_create_full_pipeline_with_predictor(pred) for pred in pds]\n",
    "\n",
    "for pipl,param in zip(pls,param):\n",
    "    pipl.fit(housing_train_X, housing_labels_train_y)\n",
    "    predictions_on_test = pipl.predict(housing_test_X)\n",
    "    print('MSE on Test Set when L1_ratio='+str(param)+':', mean_squared_error(housing_labels_test_y, predictions_on_test))\n",
    "print('MSE on Test Set of inclass OLS:',lin_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python369jvsc74a57bd03d88cacd8b745d4fbed2830424fce0451ea91f459b833c1d75c3abe001a2f0c4",
   "display_name": "Python 3.6.9 64-bit ('mysixenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}